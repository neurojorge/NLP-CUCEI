{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "import time\n",
    "\n",
    "class IndexadorChatCUCEI:\n",
    "    def __init__(self, persist_dir=\"./chroma_db\"):\n",
    "        \"\"\"\n",
    "        Inicializa el sistema de indexación\n",
    "        \n",
    "        Args:\n",
    "            persist_dir: Directorio donde se guardará ChromaDB\n",
    "        \"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"INDEXADOR ChatCUCEI - Sistema RAG Optimizado\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        \n",
    "        print(\"\\nCargando modelo de embeddings...\")\n",
    "        self.embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "        print(\" Modelo cargado: paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "        \n",
    "        \n",
    "        print(f\"Inicializando ChromaDB en: {persist_dir}\")\n",
    "        self.client = chromadb.PersistentClient(path=persist_dir)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            self.collection = self.client.get_collection(\"profesores_cucei\")\n",
    "            print(f\"✅ Colección existente: {self.collection.count()} documentos\")\n",
    "        except:\n",
    "            self.collection = self.client.create_collection(\n",
    "                name=\"profesores_cucei\",\n",
    "                metadata={\"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "            print(\"✅ Nueva colección creada\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalizar_nombre(nombre: str) -> str:\n",
    "        \n",
    "        \n",
    "        nombre = nombre.replace('\"', '').replace(\"'\", '')\n",
    "        \n",
    "        \n",
    "        nombre = nombre.replace(',', ' ')\n",
    "        nombre = ' '.join(nombre.split())  \n",
    "        \n",
    "        \n",
    "        nombre = nombre.upper()\n",
    "        \n",
    "       \n",
    "        nombre = unicodedata.normalize('NFKD', nombre)\n",
    "        nombre = ''.join([c for c in nombre if not unicodedata.combining(c)])\n",
    "        \n",
    "        return nombre.strip()\n",
    "    \n",
    "    def limpiar_comentario(self, comentario: str) -> Optional[str]:\n",
    "       \n",
    "        if pd.isna(comentario) or not comentario:\n",
    "            return None\n",
    "        \n",
    "        comentario = str(comentario).strip()\n",
    "        \n",
    "        \n",
    "        comentario = re.sub(r'^Calificación:\\s*\\d+\\.?\\d*/10\\s*-?\\s*', '', comentario)\n",
    "        \n",
    "        \n",
    "        if comentario in ['(No hay información del maestro)', '', 'N/A', 'nan']:\n",
    "            return None\n",
    "        \n",
    "        if len(comentario) < 10:  \n",
    "            return None\n",
    "        \n",
    "        return comentario.strip()\n",
    "    \n",
    "    def extraer_calificacion(self, texto: str) -> float:\n",
    "        \n",
    "        match = re.search(r'Calificación:\\s*(\\d+\\.?\\d*)/10', texto)\n",
    "        return float(match.group(1)) if match else 0.0\n",
    "    \n",
    "    def extraer_tags(self, texto: str, max_tags: int = 5) -> List[str]:\n",
    "       \n",
    "        if \" - \" not in texto:\n",
    "            return []\n",
    "        \n",
    "        \n",
    "        tags_text = texto.split(\" - \", 1)[1]\n",
    "        \n",
    "       \n",
    "        tags = []\n",
    "        for tag in tags_text.split(\",\"):\n",
    "            tag = tag.strip().upper()\n",
    "            if tag and len(tag) > 2:  \n",
    "                tags.append(tag)\n",
    "        \n",
    "        return tags[:max_tags]\n",
    "    \n",
    "    def crear_documento_embedding(self, row: pd.Series, comentario_limpio: str) -> str:\n",
    "       \n",
    "        profesor = row['PROFESOR']\n",
    "        materia = row['MATERIA'] if pd.notna(row['MATERIA']) else \"\"\n",
    "        depto = row['DEPARTAMENTO'] if pd.notna(row['DEPARTAMENTO']) else \"\"\n",
    "        calificacion = self.extraer_calificacion(row['COMENTARIOS'])\n",
    "        tags = self.extraer_tags(row['COMENTARIOS'])\n",
    "        \n",
    "       \n",
    "        documento = f\"\"\"\n",
    "        Profesor: {profesor}\n",
    "        Nombre del maestro: {profesor}\n",
    "        Evaluación del profesor {profesor}\n",
    "        Materia: {materia}\n",
    "        Departamento: {depto}\n",
    "        Calificación: {calificacion}/10\n",
    "        Características: {', '.join(tags) if tags else 'N/A'}\n",
    "        Comentarios: {comentario_limpio}\n",
    "        \"\"\".strip()\n",
    "        \n",
    "        return documento\n",
    "    \n",
    "    def indexar_csv(self, csv_path: str, batch_size: int = 100):\n",
    "      \n",
    "        print(f\"{'='*70}\")\n",
    "        print(\"INICIANDO INDEXACIÓN\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "       \n",
    "        csv_path = Path(csv_path)\n",
    "        if not csv_path.exists():\n",
    "            raise FileNotFoundError(f\"No se encuentra: {csv_path}\")\n",
    "        \n",
    "        print(f\" Archivo: {csv_path.name}\")\n",
    "        \n",
    "        \n",
    "        print(\" Leyendo CSV...\")\n",
    "        df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "        print(f\"   Total filas: {len(df):,}\")\n",
    "        \n",
    "        \n",
    "        documentos = []\n",
    "        metadatas = []\n",
    "        ids = []\n",
    "        \n",
    "        stats = {\n",
    "            'total': len(df),\n",
    "            'procesados': 0,\n",
    "            'omitidos': 0,\n",
    "            'sin_comentarios': 0,\n",
    "            'sin_profesor': 0\n",
    "        }\n",
    "        \n",
    "        print(\"\\n Procesando datos...\")\n",
    "        inicio = time.time()\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            \n",
    "            if pd.isna(row['PROFESOR']) or not str(row['PROFESOR']).strip():\n",
    "                stats['sin_profesor'] += 1\n",
    "                stats['omitidos'] += 1\n",
    "                continue\n",
    "            \n",
    "            profesor = str(row['PROFESOR']).strip()\n",
    "            profesor_normalizado = self.normalizar_nombre(profesor)\n",
    "            \n",
    "            \n",
    "            comentario_limpio = self.limpiar_comentario(row['COMENTARIOS'])\n",
    "            if not comentario_limpio:\n",
    "                stats['sin_comentarios'] += 1\n",
    "                stats['omitidos'] += 1\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            comentarios_original = str(row['COMENTARIOS'])\n",
    "            calificacion = self.extraer_calificacion(comentarios_original)\n",
    "            tags = self.extraer_tags(comentarios_original)\n",
    "            \n",
    "            materia = str(row['MATERIA']) if pd.notna(row['MATERIA']) else \"\"\n",
    "            depto = str(row['DEPARTAMENTO']) if pd.notna(row['DEPARTAMENTO']) else \"\"\n",
    "            division = str(row['DIVISION']) if 'DIVISION' in row and pd.notna(row['DIVISION']) else \"\"\n",
    "            \n",
    "            \n",
    "            documento = self.crear_documento_embedding(row, comentario_limpio)\n",
    "            documentos.append(documento)\n",
    "            \n",
    "            \n",
    "            metadatas.append({\n",
    "                \"profesor\": profesor,\n",
    "                \"profesor_normalizado\": profesor_normalizado,\n",
    "                \"materia\": materia,\n",
    "                \"departamento\": depto,\n",
    "                \"division\": division,\n",
    "                \"calificacion\": float(calificacion),\n",
    "                \"tags\": \", \".join(tags) if tags else \"\",\n",
    "                \"comentarios\": comentario_limpio,\n",
    "                \"comentarios_original\": comentarios_original\n",
    "            })\n",
    "            \n",
    "            ids.append(f\"resena_{idx}\")\n",
    "            stats['procesados'] += 1\n",
    "            \n",
    "            \n",
    "            if (idx + 1) % 500 == 0:\n",
    "                print(f\"   Procesados: {idx + 1:,}/{len(df):,}\")\n",
    "        \n",
    "        print(f\"\\n Procesamiento completado en {time.time() - inicio:.2f}s\")\n",
    "        print(f\"\\n Resumen:\")\n",
    "        print(f\"   Total filas: {stats['total']:,}\")\n",
    "        print(f\"   Procesados: {stats['procesados']:,}\")\n",
    "        print(f\"   Omitidos: {stats['omitidos']:,}\")\n",
    "        print(f\"     - Sin profesor: {stats['sin_profesor']:,}\")\n",
    "        print(f\"     - Sin comentarios válidos: {stats['sin_comentarios']:,}\")\n",
    "        \n",
    "        \n",
    "        print(f\"\\n Generando embeddings e indexando en ChromaDB...\")\n",
    "        print(f\"   Batch size: {batch_size}\")\n",
    "        \n",
    "        inicio = time.time()\n",
    "        \n",
    "        for i in range(0, len(documentos), batch_size):\n",
    "            batch_docs = documentos[i:i+batch_size]\n",
    "            batch_metas = metadatas[i:i+batch_size]\n",
    "            batch_ids = ids[i:i+batch_size]\n",
    "            \n",
    "            self.collection.add(\n",
    "                documents=batch_docs,\n",
    "                metadatas=batch_metas,\n",
    "                ids=batch_ids\n",
    "            )\n",
    "            \n",
    "            if (i + batch_size) % 500 == 0 or i + batch_size >= len(documentos):\n",
    "                current = min(i + batch_size, len(documentos))\n",
    "                print(f\"   ✓ {current:,}/{len(documentos):,} indexados\")\n",
    "        \n",
    "        tiempo_indexacion = time.time() - inicio\n",
    "        \n",
    "        print(f\"\\n Indexación completada en {tiempo_indexacion:.2f}s\")\n",
    "        print(f\" Total documentos en ChromaDB: {self.collection.count():,}\")\n",
    "        print(f\" Velocidad: {len(documentos)/tiempo_indexacion:.1f} docs/segundo\")\n",
    "    \n",
    "    def verificar_indexacion(self, n_samples: int = 5):\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"VERIFICACIÓN DE INDEXACIÓN\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        total = self.collection.count()\n",
    "        print(f\" Total documentos: {total:,}\\n\")\n",
    "        \n",
    "        if total == 0:\n",
    "            print(\"  Base de datos vacía\")\n",
    "            return\n",
    "        \n",
    "        \n",
    "        peek = self.collection.peek(limit=n_samples)\n",
    "        \n",
    "        print(f\" Muestra de {n_samples} documentos:\\n\")\n",
    "        \n",
    "        for i, (doc, meta) in enumerate(zip(peek['documents'], peek['metadatas']), 1):\n",
    "            print(f\"{'─'*70}\")\n",
    "            print(f\"Documento #{i}\")\n",
    "            print(f\"{'─'*70}\")\n",
    "            print(f\"Profesor: {meta['profesor']}\")\n",
    "            print(f\"Normalizado: {meta['profesor_normalizado']}\")\n",
    "            print(f\"Calificación: {meta['calificacion']}/10\")\n",
    "            if meta['tags']:\n",
    "                tags_preview = ', '.join(meta['tags'].split(',')[:3])\n",
    "                print(f\"Tags: {tags_preview}\")\n",
    "            if meta['materia']:\n",
    "                print(f\"Materia: {meta['materia']}\")\n",
    "            print(f\"Comentario: {meta['comentarios'][:100]}...\")\n",
    "            print()\n",
    "        \n",
    "        \n",
    "        print(f\"{'─'*70}\")\n",
    "        print(\" Estadísticas generales:\")\n",
    "        print(f\"   Total profesores únicos: ~{total//5} (estimado)\")\n",
    "        print(f\"   Promedio reseñas/profesor: ~5\")\n",
    "        print(f\"{'─'*70}\\n\")\n",
    "    \n",
    "    def test_busqueda(self, queries: List[str], n_results: int = 3):\n",
    "       \n",
    "        print(f\"{'='*70}\")\n",
    "        print(\"PRUEBA DE BÚSQUEDA\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        for i, query in enumerate(queries, 1):\n",
    "            print(f\"{'─'*70}\")\n",
    "            print(f\"Query #{i}: {query}\")\n",
    "            print(f\"{'─'*70}\")\n",
    "            \n",
    "            results = self.collection.query(\n",
    "                query_texts=[query],\n",
    "                n_results=n_results\n",
    "            )\n",
    "            \n",
    "            if not results['metadatas'][0]:\n",
    "                print(\"⚠️  Sin resultados\\n\")\n",
    "                continue\n",
    "            \n",
    "            for j, meta in enumerate(results['metadatas'][0], 1):\n",
    "                print(f\"\\nResultado {j}:\")\n",
    "                print(f\"  Profesor: {meta['profesor']}\")\n",
    "                print(f\"  Calificación: {meta['calificacion']}/10\")\n",
    "                if meta['tags']:\n",
    "                    print(f\"  Tags: {meta['tags'][:60]}...\")\n",
    "                print(f\"  Comentario: {meta['comentarios'][:120]}...\")\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    def reiniciar(self):\n",
    "        \n",
    "        print(\"\\n  REINICIANDO BASE DE DATOS...\")\n",
    "        try:\n",
    "            self.client.delete_collection(\"profesores_cucei\")\n",
    "            print(\" Colección borrada\")\n",
    "        except:\n",
    "            print(\" No había colección previa\")\n",
    "        \n",
    "        self.collection = self.client.create_collection(\n",
    "            name=\"profesores_cucei\",\n",
    "            metadata={\"hnsw:space\": \"cosine\"}\n",
    "        )\n",
    "        print(\" Nueva colección creada\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    CSV_PATH = r\"# === NOTE: Replace with local path ===\"\n",
    "    CHROMA_DB_PATH = \"./chroma_db\"\n",
    "  \n",
    "    indexador = IndexadorChatCUCEI(persist_dir=CHROMA_DB_PATH)\n",
    "    \n",
    "    \n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"MENÚ DE INDEXACIÓN\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    documentos_existentes = indexador.collection.count()\n",
    "    \n",
    "    if documentos_existentes > 0:\n",
    "        print(f\" Base de datos existente: {documentos_existentes:,} documentos\\n\")\n",
    "        print(\"Opciones:\")\n",
    "        print(\"  1. Usar datos existentes (verificar)\")\n",
    "        print(\"  2. Re-indexar desde cero (BORRA datos existentes)\")\n",
    "        print(\"  3. Ver estadísticas\")\n",
    "        print(\"  4. Probar búsquedas\")\n",
    "        print(\"  5. Salir\")\n",
    "        \n",
    "        opcion = input(\"\\nSelecciona (1-5): \").strip()\n",
    "        \n",
    "        if opcion == \"1\":\n",
    "            indexador.verificar_indexacion(n_samples=10)\n",
    "            \n",
    "        elif opcion == \"2\":\n",
    "            confirmacion = input(\"\\n  Esto borrará todos los datos. ¿Continuar? (si/no): \")\n",
    "            if confirmacion.lower() in ['si', 's', 'yes', 'y']:\n",
    "                indexador.reiniciar()\n",
    "                indexador.indexar_csv(CSV_PATH)\n",
    "                indexador.verificar_indexacion()\n",
    "            else:\n",
    "                print(\" Operación cancelada\")\n",
    "                \n",
    "        elif opcion == \"3\":\n",
    "            indexador.verificar_indexacion(n_samples=10)\n",
    "            \n",
    "        elif opcion == \"4\":\n",
    "            test_queries = [\n",
    "                \"¿Qué opinas de ABEL MARQUEZ SOTO?\",\n",
    "                \"¿Cómo es ELIZABETH ACEVES FERNANDEZ?\",\n",
    "                \"Recomiendas a ADRIAN CERVANTES LOMELI?\",\n",
    "                \"Info sobre MIGUEL ABUNDIS SANCHEZ\"\n",
    "            ]\n",
    "            indexador.test_busqueda(test_queries)\n",
    "            \n",
    "        else:\n",
    "            print(\" Saliendo...\")\n",
    "            return\n",
    "    \n",
    "    else:\n",
    "        print(\"  Base de datos vacía\\n\")\n",
    "        print(\"Iniciando indexación completa...\")\n",
    "        indexador.indexar_csv(CSV_PATH)\n",
    "        indexador.verificar_indexacion()\n",
    "        \n",
    "       \n",
    "        print(\"\\n¿Ejecutar pruebas de búsqueda? (s/n): \", end=\"\")\n",
    "        if input().lower() in ['s', 'si', 'y', 'yes']:\n",
    "            test_queries = [\n",
    "                \"¿Qué opinas de ABEL MARQUEZ SOTO?\",\n",
    "                \"¿Cómo es ELIZABETH ACEVES FERNANDEZ?\",\n",
    "                \"Recomiendas a ADRIAN CERVANTES?\"\n",
    "            ]\n",
    "            indexador.test_busqueda(test_queries)\n",
    "    \n",
    "    # Mensaje final\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\" INDEXACIÓN COMPLETADA\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\n Base de datos lista en: {CHROMA_DB_PATH}\")\n",
    "    print(f\" Total documentos: {indexador.collection.count():,}\")\n",
    "    print(f\"\\n SIGUIENTE PASO:\")\n",
    "    print(f\"   Ejecuta tu script de fine-tuning:\")\n",
    "    print(f\"   python train_phi3_hybrid.py\")\n",
    "    print(f\"\\n   O prueba inferencia directa:\")\n",
    "    print(f\"   python inference_hybrid.py\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

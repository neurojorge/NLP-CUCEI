{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1. Generar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(f\"üî• CUDA disponible: {torch.cuda.is_available()}\")\n",
    "print(f\" GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No detectada'}\")\n",
    "print(f\" VRAM disponible: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "# %%\n",
    "def clean_text(text):\n",
    "    \"\"\"Limpiar texto en espa√±ol\"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    # Remover patr√≥n de calificaci√≥n\n",
    "    text = re.sub(r'Calificaci√≥n:\\s*[\\d\\.]+/10\\s*-\\s*', '', text)\n",
    "    # Normalizar espacios\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_rating(text):\n",
    "    \"\"\"Extraer calificaci√≥n del comentario\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    match = re.search(r'Calificaci√≥n:\\s*([\\d\\.]+)/10', str(text))\n",
    "    if match:\n",
    "        try:\n",
    "            return float(match.group(1))\n",
    "        except:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def create_enriched_text(row):\n",
    "    \"\"\"Crear texto enriquecido con contexto\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Departamento\n",
    "    if pd.notna(row['DEPARTAMENTO']) and row['DEPARTAMENTO'] != \"\":\n",
    "        dept = str(row['DEPARTAMENTO']).replace('DEPTO. DE ', '').strip()\n",
    "        parts.append(f\"Departamento: {dept}\")\n",
    "    \n",
    "    # Divisi√≥n\n",
    "    if pd.notna(row['DIVISION']) and row['DIVISION'] != \"\":\n",
    "        div = str(row['DIVISION']).replace('Divisi√≥n de ', '').strip()\n",
    "        parts.append(f\"Divisi√≥n: {div}\")\n",
    "    \n",
    "    # Materia\n",
    "    if pd.notna(row['MATERIA']) and str(row['MATERIA']).strip() != \"\":\n",
    "        materia = re.sub(r'\\([^)]*\\)', '', str(row['MATERIA'])).strip()\n",
    "        if materia:\n",
    "            parts.append(f\"Materia: {materia}\")\n",
    "    \n",
    "    # Comentario\n",
    "    comment = clean_text(row['COMENTARIOS'])\n",
    "    if comment:\n",
    "        parts.append(f\"Comentario: {comment}\")\n",
    "    \n",
    "    return \" | \".join(parts)\n",
    "\n",
    "print(\"‚úÖ Funciones de preprocesamiento listas\")\n",
    "\n",
    "# %%\n",
    "# Configuraci√≥n de rutas\n",
    "CSV_PATH = r\"# === NOTE: Replace with local path ===\"\n",
    "OUTPUT_DIR = r\"# === NOTE: Replace with local path ===\"\n",
    "\n",
    "print(f\" CSV: {CSV_PATH}\")\n",
    "print(f\" Salida: {OUTPUT_DIR}\")\n",
    "\n",
    "# Crear directorio de salida\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# %%\n",
    "# Cargar datos\n",
    "print(\" Cargando datos...\")\n",
    "df = pd.read_csv(CSV_PATH, encoding='utf-8')\n",
    "\n",
    "print(f\"‚úÖ Dataset cargado:\")\n",
    "print(f\"  ‚Ä¢ Total filas: {len(df)}\")\n",
    "print(f\"  ‚Ä¢ Profesores √∫nicos: {df['PROFESOR'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Departamentos: {df['DEPARTAMENTO'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Comentarios v√°lidos: {df['COMENTARIOS'].notna().sum()}\")\n",
    "\n",
    "# %%\n",
    "# Preparar datos para embeddings\n",
    "print(\"üîß Preparando datos...\")\n",
    "\n",
    "# Extraer ratings\n",
    "df['rating'] = df['COMENTARIOS'].apply(extract_rating)\n",
    "\n",
    "# Crear textos enriquecidos\n",
    "df['texto_enriquecido'] = df.apply(create_enriched_text, axis=1)\n",
    "\n",
    "# Filtrar datos √∫tiles\n",
    "mask = (df['texto_enriquecido'].str.len() > 15) & (df['COMENTARIOS'].notna())\n",
    "df_clean = df[mask].copy()\n",
    "\n",
    "print(f\"‚úÖ Datos preparados:\")\n",
    "print(f\"  ‚Ä¢ Filas √∫tiles: {len(df_clean)}\")\n",
    "print(f\"  ‚Ä¢ Ratings extra√≠dos: {df_clean['rating'].notna().sum()}\")\n",
    "print(f\"  ‚Ä¢ Rating promedio: {df_clean['rating'].mean():.2f}\")\n",
    "\n",
    "# Mostrar ejemplos\n",
    "print(f\"\\nüìù Ejemplos de textos enriquecidos:\")\n",
    "for i in range(min(3, len(df_clean))):\n",
    "    text = df_clean.iloc[i]['texto_enriquecido']\n",
    "    print(f\"  {i+1}. {text[:120]}...\")\n",
    "\n",
    "# %%\n",
    "# Modelos disponibles optimizados para espa√±ol\n",
    "MODELS = {\n",
    "    'spanish_specialized': 'hiiamsid/sentence_transformers_spanish',\n",
    "    'multilingual_robust': 'paraphrase-multilingual-MiniLM-L12-v2',\n",
    "    'academic_optimized': 'distiluse-base-multilingual-cased'\n",
    "}\n",
    "\n",
    "# Seleccionar modelo (cambia aqu√≠ si quieres)\n",
    "MODEL_CHOICE = 'multilingual_robust'  # Recomendado para espa√±ol latinoamericano\n",
    "model_name = MODELS[MODEL_CHOICE]\n",
    "\n",
    "print(f\" Cargando modelo: {model_name}\")\n",
    "\n",
    "#\n",
    "# Cargar modelo con optimizaci√≥n GPU\n",
    "try:\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Configurar para RTX 3050\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        torch.cuda.empty_cache()  # Limpiar VRAM\n",
    "        \n",
    "    else:\n",
    "        print(\" Usando CPU\")\n",
    "    \n",
    "    print(f\" Modelo '{MODEL_CHOICE}' listo\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"üîÑ Probando modelo alternativo...\")\n",
    "    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "    MODEL_CHOICE = 'multilingual_robust'\n",
    "\n",
    "\n",
    "# Generar embeddings con optimizaci√≥n GPU\n",
    "print(f\"üöÄ Generando embeddings para {len(df_clean)} textos...\")\n",
    "\n",
    "texts = df_clean['texto_enriquecido'].tolist()\n",
    "\n",
    "# Batch size optimizado \n",
    "BATCH_SIZE = 32  # Ajusta si necesitas (16 para m√°s seguridad, 64 para m√°s velocidad)\n",
    "\n",
    "try:\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    print(f\" Embeddings generados:\")\n",
    "    print(f\"  ‚Ä¢ Dimensiones: {embeddings.shape}\")\n",
    "    print(f\"  ‚Ä¢ Memoria usada: {embeddings.nbytes / 1024**2:.1f} MB\")\n",
    "    print(f\"  ‚Ä¢ Normalizado: S√≠\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    embeddings = None\n",
    "\n",
    "# %%\n",
    "# Crear estructura de datos completa\n",
    "if embeddings is not None:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    embeddings_package = {\n",
    "        'embeddings': embeddings,\n",
    "        'metadata': {\n",
    "            'model_choice': MODEL_CHOICE,\n",
    "            'model_name': model_name,\n",
    "            'embedding_dim': embeddings.shape[1],\n",
    "            'num_samples': embeddings.shape[0],\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'normalized': True,\n",
    "            'device_used': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "            'generation_date': datetime.now().isoformat()\n",
    "        },\n",
    "        'data': {\n",
    "            'professors': df_clean['PROFESOR'].tolist(),\n",
    "            'departments': df_clean['DEPARTAMENTO'].tolist(),\n",
    "            'divisions': df_clean['DIVISION'].tolist(),\n",
    "            'subjects': df_clean['MATERIA'].tolist(),\n",
    "            'ratings': df_clean['rating'].tolist(),\n",
    "            'original_comments': df_clean['COMENTARIOS'].tolist(),\n",
    "            'enriched_texts': texts\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\" Paquete de datos creado\")\n",
    "\n",
    "# %%\n",
    "# Guardar embeddings\n",
    "if embeddings is not None:\n",
    "    \n",
    "    # Crear nombres de archivos\n",
    "    base_name = f\"profesores_embeddings_{MODEL_CHOICE}_{timestamp}\"\n",
    "    \n",
    "    # 1. Embeddings puros (numpy) - Para cargar r√°pido\n",
    "    embeddings_file = os.path.join(OUTPUT_DIR, f\"{base_name}.npy\")\n",
    "    np.save(embeddings_file, embeddings)\n",
    "    \n",
    "    # 2. Paquete completo (pickle) - Para an√°lisis completo\n",
    "    complete_file = os.path.join(OUTPUT_DIR, f\"{base_name}_complete.pkl\")\n",
    "    with open(complete_file, 'wb') as f:\n",
    "        pickle.dump(embeddings_package, f)\n",
    "    \n",
    "    # 3. Metadatos (JSON) - Para referencia r√°pida\n",
    "    metadata_file = os.path.join(OUTPUT_DIR, f\"{base_name}_metadata.json\")\n",
    "    with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "        metadata_summary = {\n",
    "            'modelo': embeddings_package['metadata'],\n",
    "            'resumen_datos': {\n",
    "                'profesores_unicos': len(set(embeddings_package['data']['professors'])),\n",
    "                'departamentos': len(set(filter(pd.notna, embeddings_package['data']['departments']))),\n",
    "                'divisiones': len(set(filter(pd.notna, embeddings_package['data']['divisions']))),\n",
    "                'rating_promedio': np.nanmean([r for r in embeddings_package['data']['ratings'] if r is not None]),\n",
    "                'total_muestras': len(embeddings_package['data']['professors'])\n",
    "            }\n",
    "        }\n",
    "        json.dump(metadata_summary, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n Archivos guardados:\")\n",
    "    print(f\"  ‚Ä¢ Embeddings: {embeddings_file}\")\n",
    "    print(f\"  ‚Ä¢ Datos completos: {complete_file}\")\n",
    "    print(f\"  ‚Ä¢ Metadatos: {metadata_file}\")\n",
    "\n",
    "# %%\n",
    "# An√°lisis de embeddings generados\n",
    "if embeddings is not None:\n",
    "    print(f\"\\n An√°lisis de embeddings:\")\n",
    "    print(f\"  ‚Ä¢ Forma: {embeddings.shape}\")\n",
    "    print(f\"  ‚Ä¢ Dimensi√≥n: {embeddings.shape[1]}\")\n",
    "    print(f\"  ‚Ä¢ Samples: {embeddings.shape[0]}\")\n",
    "    print(f\"  ‚Ä¢ Rango valores: [{embeddings.min():.4f}, {embeddings.max():.4f}]\")\n",
    "    print(f\"  ‚Ä¢ Media: {embeddings.mean():.4f}\")\n",
    "    print(f\"  ‚Ä¢ Std: {embeddings.std():.4f}\")\n",
    "    \n",
    "    # Verificar normalizaci√≥n\n",
    "    norms = np.linalg.norm(embeddings, axis=1)\n",
    "    print(f\"  ‚Ä¢ Normas L2: min={norms.min():.4f}, max={norms.max():.4f}\")\n",
    "    \n",
    "    # Estad√≠sticas por departamento\n",
    "    dept_stats = df_clean.groupby('DEPARTAMENTO').agg({\n",
    "        'rating': ['count', 'mean'],\n",
    "        'PROFESOR': 'nunique'\n",
    "    }).round(2)\n",
    "    \n",
    "    print(f\"\\nüìä Estad√≠sticas por departamento:\")\n",
    "    print(dept_stats.head())\n",
    "\n",
    "# %%\n",
    "print(\"\\nüéâ ¬°Embeddings generados exitosamente!\")\n",
    "print(\" Archivos listos en:\", OUTPUT_DIR)\n",
    "print(\"\\n Pr√≥ximos pasos:\")\n",
    "print(\"  1. ‚úÖ Embeddings base generados\")\n",
    "print(\"  2. üîÑ Siguiente: Red neuronal con attention\")\n",
    "\n",
    "# %%\n",
    "# Funci√≥n para cargar embeddings despu√©s (para uso futuro)\n",
    "def load_embeddings(embeddings_dir, timestamp=None):\n",
    "    \"\"\"\n",
    "    Funci√≥n para cargar embeddings generados\n",
    "    Si timestamp=None, carga el m√°s reciente\n",
    "    \"\"\"\n",
    "    files = list(Path(embeddings_dir).glob(\"*_complete.pkl\"))\n",
    "    if not files:\n",
    "        print(\" No se encontraron archivos de embeddings\")\n",
    "        return None\n",
    "    \n",
    "    if timestamp:\n",
    "        target_file = [f for f in files if timestamp in str(f)]\n",
    "        if target_file:\n",
    "            file_to_load = target_file[0]\n",
    "        else:\n",
    "            print(f\" No se encontr√≥ archivo con timestamp {timestamp}\")\n",
    "            return None\n",
    "    else:\n",
    "        # Cargar el m√°s reciente\n",
    "        file_to_load = max(files, key=os.path.getctime)\n",
    "    \n",
    "    print(f\" Cargando: {file_to_load}\")\n",
    "    \n",
    "    with open(file_to_load, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    print(f\" Embeddings cargados: {data['embeddings'].shape}\")\n",
    "    return data\n",
    "\n",
    "print(\" Funci√≥n de carga definida para uso futuro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "class ChatCUCEI:\n",
    "    def __init__(self, base_model=\"microsoft/Phi-3-mini-4k-instruct\", chroma_db_path=\"./chroma_db\"):\n",
    "        print(\"Inicializando ChatCUCEI...\")\n",
    "        \n",
    "        # RAG\n",
    "        self.embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "        self.chroma_client = chromadb.PersistentClient(path=chroma_db_path)\n",
    "        self.collection = self.chroma_client.get_collection(\"profesores_cucei\")\n",
    "        print(f\"RAG: {self.collection.count()} documentos cargados\")\n",
    "        \n",
    "        # LLM\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            base_model, \n",
    "            torch_dtype=torch.bfloat16, \n",
    "            device_map=\"auto\", \n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        self.model.eval()\n",
    "        print(\"Modelo cargado y listo\\n\")\n",
    "    \n",
    "    def normalizar_nombre(self, texto: str) -> str:\n",
    "        \"\"\"Normaliza un nombre para comparacion\"\"\"\n",
    "        stopwords = {'del', 'de', 'la', 'el', 'profesor', 'profesora', 'profes', 'profe', \n",
    "                    'que', 'como', 'es', 'opinas', 'recomiendas', 'sobre', 'a', 'quien',\n",
    "                    'mejor', 'o'}\n",
    "        \n",
    "        texto = re.sub(r'[¿?¡!,.]', '', texto.lower())\n",
    "        palabras = [p for p in texto.split() if p not in stopwords and len(p) > 1]\n",
    "        return ' '.join(palabras).upper()\n",
    "    \n",
    "    def extraer_nombres(self, query: str) -> List[str]:\n",
    "        \"\"\"Extrae multiples nombres de una query\"\"\"\n",
    "        query_limpia = re.sub(r'[¿?¡!,.]', '', query.lower())\n",
    "        \n",
    "        # Detectar comparaciones\n",
    "        if ' o ' in query_limpia:\n",
    "            partes = query_limpia.split(' o ')\n",
    "            return [self.normalizar_nombre(p) for p in partes if self.normalizar_nombre(p)]\n",
    "        \n",
    "        return [self.normalizar_nombre(query)]\n",
    "    \n",
    "    def similitud_rapida(self, nombre1: str, nombre2: str) -> float:\n",
    "        \"\"\"Calcula similitud simple y rapida\"\"\"\n",
    "        palabras1 = set(nombre1.split())\n",
    "        palabras2 = set(nombre2.split())\n",
    "        \n",
    "        if not palabras1 or not palabras2:\n",
    "            return 0.0\n",
    "        \n",
    "        interseccion = len(palabras1 & palabras2)\n",
    "        union = len(palabras1 | palabras2)\n",
    "        \n",
    "        return interseccion / union if union > 0 else 0.0\n",
    "    \n",
    "    def buscar_mejor_match(self, nombre_query: str, candidatos: List[Dict]) -> Tuple[Optional[str], float]:\n",
    "        \"\"\"Encuentra el mejor match de forma eficiente\"\"\"\n",
    "        if not nombre_query:\n",
    "            return None, 0.0\n",
    "        \n",
    "        print(f\"Buscando: '{nombre_query}'\")\n",
    "        \n",
    "        mejor_profesor = None\n",
    "        mejor_score = 0.0\n",
    "        profesores_vistos = set()\n",
    "        \n",
    "        for meta in candidatos:\n",
    "            prof_norm = meta['profesor_normalizado']\n",
    "            \n",
    "            if prof_norm in profesores_vistos:\n",
    "                continue\n",
    "            \n",
    "            profesores_vistos.add(prof_norm)\n",
    "            score = self.similitud_rapida(nombre_query, prof_norm)\n",
    "            \n",
    "            if score > mejor_score:\n",
    "                mejor_score = score\n",
    "                mejor_profesor = prof_norm\n",
    "        \n",
    "        if mejor_score < 0.3:\n",
    "            print(f\"No se encontro match confiable\")\n",
    "            return None, mejor_score\n",
    "        \n",
    "        print(f\"Encontrado: {mejor_profesor} (similitud: {mejor_score:.2f})\")\n",
    "        return mejor_profesor, mejor_score\n",
    "    \n",
    "    def buscar_contexto(self, query: str, n_results: int = 25) -> Optional[Dict]:\n",
    "        \"\"\"Busca contexto relevante\"\"\"\n",
    "        results = self.collection.query(query_texts=[query], n_results=n_results)\n",
    "        \n",
    "        if not results['documents'][0]:\n",
    "            return None\n",
    "        \n",
    "        nombres = self.extraer_nombres(query)\n",
    "        mejor_match, score = self.buscar_mejor_match(nombres[0], results['metadatas'][0])\n",
    "        \n",
    "        if not mejor_match:\n",
    "            return None\n",
    "        \n",
    "        calificaciones = []\n",
    "        tags = set()\n",
    "        comentarios = []\n",
    "        nombre_original = None\n",
    "        \n",
    "        for meta in results['metadatas'][0]:\n",
    "            if meta['profesor_normalizado'] == mejor_match:\n",
    "                if not nombre_original:\n",
    "                    nombre_original = meta['profesor']\n",
    "                \n",
    "                if meta.get('calificacion', 0) > 0:\n",
    "                    calificaciones.append(meta['calificacion'])\n",
    "                \n",
    "                if meta.get('tags'):\n",
    "                    tags.update(meta['tags'].split(\", \"))\n",
    "                \n",
    "                if meta.get('comentarios'):\n",
    "                    comentarios.append(meta['comentarios'])\n",
    "        \n",
    "        comentarios_ordenados = sorted(comentarios, key=len, reverse=True)\n",
    "        \n",
    "        return {\n",
    "            \"profesor\": nombre_original,\n",
    "            \"calificacion_promedio\": sum(calificaciones) / len(calificaciones) if calificaciones else None,\n",
    "            \"num_calificaciones\": len(calificaciones),\n",
    "            \"tags\": list(tags)[:5],\n",
    "            \"comentarios\": comentarios_ordenados[:2],\n",
    "            \"confianza\": score\n",
    "        }\n",
    "    \n",
    "    def buscar_comparacion(self, query: str) -> Optional[Dict]:\n",
    "        \"\"\"Busca informacion para comparar dos profesores\"\"\"\n",
    "        nombres = self.extraer_nombres(query)\n",
    "        \n",
    "        if len(nombres) < 2:\n",
    "            return None\n",
    "        \n",
    "        print(f\"Comparando profesores...\")\n",
    "        \n",
    "        resultados = {}\n",
    "        for nombre in nombres[:2]:\n",
    "            results = self.collection.query(query_texts=[nombre], n_results=20)\n",
    "            if not results['documents'][0]:\n",
    "                continue\n",
    "            \n",
    "            mejor_match, score = self.buscar_mejor_match(nombre, results['metadatas'][0])\n",
    "            if not mejor_match or score < 0.3:\n",
    "                continue\n",
    "            \n",
    "            calificaciones = []\n",
    "            tags = set()\n",
    "            nombre_original = None\n",
    "            \n",
    "            for meta in results['metadatas'][0]:\n",
    "                if meta['profesor_normalizado'] == mejor_match:\n",
    "                    if not nombre_original:\n",
    "                        nombre_original = meta['profesor']\n",
    "                    if meta.get('calificacion', 0) > 0:\n",
    "                        calificaciones.append(meta['calificacion'])\n",
    "                    if meta.get('tags'):\n",
    "                        tags.update(meta['tags'].split(\", \"))\n",
    "            \n",
    "            if nombre_original:\n",
    "                resultados[nombre_original] = {\n",
    "                    \"calificacion\": sum(calificaciones) / len(calificaciones) if calificaciones else None,\n",
    "                    \"tags\": list(tags)[:3],\n",
    "                    \"num_evaluaciones\": len(calificaciones)\n",
    "                }\n",
    "        \n",
    "        return resultados if len(resultados) >= 2 else None\n",
    "    \n",
    "    def construir_prompt(self, info: Dict, query: str) -> str:\n",
    "        \"\"\"Construye el prompt para el modelo\"\"\"\n",
    "        contexto = f\"Profesor: {info['profesor']}\\n\"\n",
    "        \n",
    "        if info['calificacion_promedio']:\n",
    "            contexto += f\"Calificacion: {info['calificacion_promedio']:.1f}/10\\n\"\n",
    "        \n",
    "        if info['tags']:\n",
    "            contexto += f\"Tags: {', '.join(info['tags'][:3])}\\n\"\n",
    "        \n",
    "        if info['comentarios']:\n",
    "            contexto += f\"Comentario: {info['comentarios'][0][:120]}...\\n\"\n",
    "        \n",
    "        prompt = (\n",
    "            f\"<|system|>Eres ChatCUCEI. Responde brevemente sobre profesores.<|end|>\"\n",
    "            f\"<|user|>{contexto}\\n{query}<|end|>\"\n",
    "            f\"<|assistant|>\"\n",
    "        )\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def generar_respuesta(self, query: str) -> str:\n",
    "        \"\"\"Genera respuesta usando RAG + LLM\"\"\"\n",
    "        # Detectar si es comparacion\n",
    "        if ' o ' in query.lower():\n",
    "            comparacion = self.buscar_comparacion(query)\n",
    "            if not comparacion:\n",
    "                return \"No se pudo encontrar informacion suficiente para comparar a esos profesores.\"\n",
    "            \n",
    "            # Respuesta directa para comparacion\n",
    "            respuesta = \"Comparacion de profesores:\\n\\n\"\n",
    "            for nombre, info in comparacion.items():\n",
    "                respuesta += f\"{nombre}:\\n\"\n",
    "                if info['calificacion']:\n",
    "                    respuesta += f\"  Calificacion: {info['calificacion']:.1f}/10 ({info['num_evaluaciones']} evaluaciones)\\n\"\n",
    "                if info['tags']:\n",
    "                    respuesta += f\"  Caracteristicas: {', '.join(info['tags'])}\\n\"\n",
    "                respuesta += \"\\n\"\n",
    "            \n",
    "            return respuesta.strip()\n",
    "        \n",
    "        # Busqueda normal\n",
    "        info = self.buscar_contexto(query)\n",
    "        \n",
    "        if not info:\n",
    "            return \"No se encontro informacion sobre ese profesor en la base de datos.\"\n",
    "        \n",
    "        prompt = self.construir_prompt(info, query)\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(self.model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=100,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        respuesta_completa = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        if \"<|assistant|>\" in respuesta_completa:\n",
    "            respuesta = respuesta_completa.split(\"<|assistant|>\")[-1].strip()\n",
    "        else:\n",
    "            respuesta = respuesta_completa.split(query)[-1].strip()\n",
    "        \n",
    "        return respuesta\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bot = ChatCUCEI()\n",
    "    \n",
    "    queries_prueba = [\n",
    "        \"¿Que opinas de Juan Carlos Corona?\",\n",
    "        \"Como es la profesora Patricia Rosario?\",\n",
    "        \"Quien es mejor Eloisa o Camino?\"\n",
    "    ]\n",
    "    \n",
    "    for q in queries_prueba:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Q: {q}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(bot.generar_respuesta(q))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
